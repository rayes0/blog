---
title: "Why Artificial Consciousness may be possible"
author: ["rayes"]
date: 2021-06-08T00:00:00-06:00
lastmod: 2022-04-06T00:00:00-06:00
tags: ["philosophy", "psychology", "intelligence"]
categories: ["AI"]
draft: false
status: "inprogress"
---

It is commonly accepted that machines cannot be conscious, and that any perceived consciousness is merely an imitation of organic consciousness. While I don't disagree with these claims, there is not much solid proof for them, though of course, the same is true for the converse. However, it is still worth considering both sides of the problem. Therefore, for arguments sake, this article will lay out a series of examples and thought experiments potentially showing that artificial conscious _could be_ possible. Keep in mind that this is mainly for speculation and interest sake. Don't take it too seriously.


# Consciousness is Physical {#consciousness-is-physical}

Consciousness is a physical property. This is contrary to what many perceive intuitively. It is instinctive to think that there is something special metaphysically in objects that are conscious which make them conscious. Another factor promoting this manner of thought may simply be our ego. We aren't willing to accept that we are purely physical beings.

However, from what we can currently observe:

-   If the physical state of the brain is changed, our consciousness appears to be altered correlationally (Eg: brain injuries like accident-induced amnesia, experiences with drugs, etc.)
-   If we physically alter the brain beyond a certain level of repair, or if blood stops flowing to the brain, we lose consciousness.
-   Larger and more physically advanced brains result with what seems to be higher levels of consciousness. However, this may just be the result of increased cognitive capabilities in areas like problem solving and a wider range of emotional expression. As will be noted later, [intelligence is not only a prerequisite for consciousness](#can-an-airplane-fly), but increased intelligence is required for greater consciousness, so this is not a problem.

As such, it seems that consciousness can be explained basically entirely from a physical point of view. This matches what we see in real life. When was the last time you thought a pen was conscious? Probably never. When was the last time you thought a dog was conscious? Probably every time you see one. What's the difference between a pen and a dog? The most obvious is physical differences. You could say that there is something outside the physical realm (like a spirit or similar, a common line of thought in various religions) which the dog has that makes it different from a pen. However, following Occam's Razor, if the difference seems to be amply explained by physical means, why resort to adding an extra layer? Note: This does not prove that intelligent design or an entity like a God doesn't exist, it merely discourages their existence (see [Doesn't the existence of an higher entity like a Spirit or God break down the theory?](#doesn-t-the-existence-of-an-higher-entity-like-a-spirit-or-god-break-down-the-theory)).

Because consciousness can be explained through physical means, and we can observe that some objects are conscious whereas others are not, then there must be physical constraints allowing certain experiences. In other words, there are some set of limitations on physical systems for consciousness to exist.


# Can an airplane fly? {#can-an-airplane-fly}

Consciousness and intelligence are connected. This is not an intuitive idea, mainly due to the fact that intelligence is often perceived as a functional, non-theoretical feature and consciousness as a theoretical one. My ideas in this section are based in large proportions on the [IIT theory](https://en.wikipedia.org/wiki/Integrated_Information_Theory), which I find particularly convincing in this area. In order to explain this further, we need to clarify a few things about information, the backbone of intelligence, and draw a connection between it and consciousness:

-   [Information is the reduction of entropy](https://en.wikipedia.org/wiki/Information_theory#Entropy_of_an_information_source). If I know one expression evaluates to a finite number of possibilities (eg: "one plus one is two"), it follows that all other possibilities are false.
-   Intelligence results simply from the flow of information in a meaningful way. What I mean by "meaningful way" is that it creates some sort of a cause and effect. Any system that does not produce a cause and effect internally on itself or externally on other systems cannot be intelligent, and in fact we can ignore these systems entirely, because they do literally nothing functionally and for our purposes may as well not be there (and according to functionalists, they don't even exist). By this definition, every object that exists and has mass is intelligent to some degree, because by simply having mass they are creating a warp in spacetime described by Einstein's general relativity, which is a case of a cause and effect relationship.
-   Using this, we can define a baseline for intelligence. Consider a hypothetical object with some mass that just sits there, creating nothing more than a curvature in spacetime. This object would be the least intelligent object we can ever get because it creates the least cause and effect reduction of entropies, so we could assign it an absolute intelligence of 0[^fn:1]. Compare this to something more intelligent, like a modern computer. By performing calculations through millions of cases of cause and effect, it is significantly more intelligent than our simple object. We could create mathematical representations for these, and this has already [been done by others](https://en.wikipedia.org/wiki/Integrated_Information_Theory#Mathematics:_formalization_of_the_postulates).
-   When we as conscious entities perceive something through an input of information consciously (I will call this an 'experience'), we are distinguishing this state from a theoretically infinite number of other possible states. What we consider non-conscious entities can only distinguish between a lesser, usually finite number of possible states (eg: A light bulb can only distinguish between two states, an 'on' state where electrons are flowing through it, and an 'off' state where electrons are not flowing through it). We can gain an intuition on how many of these states an entity can distinguish between by looking at the cause and effect relationships. Eg: An object creates a force on other objects inversely proportional to the distance between them if it has mass, otherwise it doesn't. A light bulb turns on when electrons flow through it, and off when they don't. A neuron in your brain depolarizes when excitatory input passes a certain threshold, otherwise it doesn't. Your brain as a conscious entity given a certain situation through via the senses can distinguish what is going on and choose a course of action from a theoretically infinite number of possible cases. Etc. However, the ability to distinguish between an infinite number of possible states is not consciousness itself, because if that is so then any entity which encodes information that can capture an infinite number of cases would also be conscious (eg: a camera). Rather it is when this information flow is integrated with other information flows (see the next point).
-   Consciousness emerges as a result of this flow of information interacting with the appropriate physical system (see [Consciousness is Physical](#consciousness-is-physical)). The appropriate physical system is one where the sub-elements of this experience are interdependent from each other and integrated in a unified way. Eg: Take for example the experience of seeing an object with your eyes. Various elements of the object are taken into account at once, such as the shape, colour, texture, etc. These are inseparable from each other (evidence: see fn[^fn:2]). You can't see something and notice _only_ it's shape, without any care about colour. It's impossible to. We have evidence for this as an indicator of consciousness because non-conscious entities do not have this integration of experience. If I take a picture with a camera, I can easily permanently remove the picture by deleting it from the memory card. I can edit the pixels to change the image to grayscale, hence removing one aspect of the information flow independent from other aspects. Contrast this to me seeing some scene with my eyes. I can't easily delete that one experience from my brain, or separate certain flows of information without effecting other experiences. This is because that scene has been integrated and intertwined in the physical structure (my mind).

If we assume these to be true, then a variety of implications follow:

-   We can't reduce consciousness to individual components because all experiences are together in one unified whole. (Thus structuralism cannot be true, at least not for explaining consciousness.)
-   Intelligence is a prerequisite for consciousness. Moreover, higher intelligence has the potential for higher consciousness because of more information flow. This is not a problem for us (at least currently) because as we have established, anything that has mass is intelligent to some degree. And when we are talking about computers being conscious or not, they all have mass.
-   This theory neither proves nor disproves the existence of a Spirit or God. Some entity like a spirit may have no mass in our dimensions, but they can 'exist' and be intelligent from our perspective if they can create casual relationships which affect our dimensions (which is claimed to happen in most religions). A hypothetical entity fitting this description could be conscious if they create the equivalent of what our minds do through the integration of information flow in whatever dimensions they are governed by. As touched on previously, Occam's razor discourages the existence of such entities, but doesn't do anything to prove they don't or can't exist. If they were to exist, they wouldn't effect the properties of consciousness either.
-   Due to consciousness being physical, dropping in and out of consciousness, or dropping to lower levels of consciousness is possible through shifting of physical state, and occurs frequently. A lower level of consciousness can result from two things: (1) The brain doing less integration of information flows, such as when someone is under the influence of certain drugs which impair brain activity. (2) The total information input is less, resulting in less information flow and which ultimately results in less integration. An example of this would be when sleeping.
-   In a conscious entity, thoughts are irreversible, they can't be deleted or cleanly overwritten, because once a certain experience is integrated with other ones, the state of the entire system can't be reversed. You may argue that forgetting something is a case against this because it seemingly deletes select thoughts cleanly. Firstly, conscious entities can't ever _completely_ forget something. What we call 'forgetting' is really just the term for when a thought has faded to the point that it can't be recalled from your consciousness and can't be accessed through normal means. This explains [numerous memory phenomena](https://en.wikipedia.org/wiki/Exceptional_memory). It also explains things like why relearning a concept is easier. For those that argue reverse causality is a case against this, see [Doesn't reverse causality break down the theory?](#doesn-t-reverse-causality-break-down-the-theory)


# Counterarguments {#counterarguments}


## What about Chinese rooms? {#chinese-rooms-can-understand}

John Searle's Chinese room thought experiment is commonly used to debunk artificial consciousness. The experiment goes like this: Suppose a non-Chinese speaker is in a room with a reference book that enables them to respond to any Chinese phrase into English and vice versa, at the level of human intelligence (in other words, it passes the [Turing test](https://en.wikipedia.org/wiki/Turing_test)). Another Chinese-speaking individual outside the room slips a note written in Chinese through a slot in the door. The non-Chinese speaker then uses the book to create a reply and returns it to the individual outside, thereby convincing the individual that there is a Chinese speaker in the room.

Searle proposed that because the individual inside the room doesn't actually understand Chinese, the individual and room only create the illusion of understanding. Therefore, a strong AI may create the illusion of consciousness but is in reality just a program following instructions, thus artificial consciousness is impossible because no matter how intelligent an AI program is, it will always be, in reality, a Chinese room where the computer is merely following code.

One common argument against this is treating the contents of the room and the man inside as a single system. Although the man himself may not understand Chinese, the man-room system as a whole does. The man is merely a utility in executing out the instructions from the book, and when the book is combined with the man, the system can "understand" Chinese. Searle replied to this by proposing the fact that if the man memorizes the handbook and does the exact same process, but in his head? He proposed that by linking the computation in one area, there is then no system, and the man himself still doesn't understand Chinese. This argument proves very little as it is still true that regardless of where the computation is taking place, the system as a whole still understands Chinese. And if the man memorized the book, I would indeed say he understands Chinese. He is able to take a Chinese phrase as input and intelligently craft a Turing-test passing reply. Isn't that what the definition of "understanding Chinese" is?

Suppose we took a car and disassembled it into small parts. Because the parts on their own can't drive, does that mean that the entire car, when put together, cannot drive? The main flaw in Searle's argument is that it doesn't take into account the fact that the man himself has no need to understand Chinese for the entire system to be able to do so (see [this](https://en.wikipedia.org/wiki/Fallacy_of_composition)). This is much like how the atoms of a biological brain don't need to be conscious for the brain as a whole to be (in fact, even large sections of the brain don't have to be, and aren't).

Sufficiently complex interactions between parts can produce properties the parts don't have alone (see [here](https://en.wikipedia.org/wiki/Emergence) and [here](https://en.wikipedia.org/wiki/Spontaneous_order)). There is no reason to believe that this doesn't extend to neurobiological processes. A sufficiently complex system (artificial or biological) can produce conscious phenomena. Consciousness in reality emerges from a system of enough complexity integrates information as described above. A system complex enough that it is able to pass the Turing test and achieve human level intelligence will already need to be as complex as the human brain itself. Given this complexity, it is possible that consciousness and understanding can emerge from an artificial Chinese room system.


## Does this mean all systems of enough complexity are conscious? {#does-this-mean-all-systems-of-enough-complexity-are-conscious}

No, because consciousness is caused by information integration, not by complexity, although more complex systems do have more potential to be conscious due to more potential for information flow. As we have talked about, because [consciousness is physical](#consciousness-is-physical), there must also be physical constraints. Certain systems cannot be conscious no matter what level of complexity they become because they do not integrate flow of information. For example, the example given earlier of a camera taking a photo. No matter how big the photo becomes, or how much bits of information flows through the camera, it does not integrate this in a meaningful way to create a conscious experience.


## Why can we assume that greater intelligence results from greater cause and effect? {#why-can-we-assume-that-greater-intelligence-results-from-greater-cause-and-effect}

Because this matches what we see in reality. Eg: A more advanced computer is more intelligent. A higher resolution camera is more intelligent. A more advanced computer program is more intelligent. More advanced neural networks [appear to be more intelligent](https://www.gwern.net/Scaling-hypothesis). Etc.

One may argue that just because something creates more impact through cause and effect does not mean it is intelligent, nor does intelligence always scale with cause and effect. And you would be right. However, the point is not that the magnitude of intelligence can be precisely measured by cause and effect, but rather that cause and effect is a prerequisite for intelligence, and that intelligence is a prerequisite for consciousness because you can't have information flow without intelligence.

tldr; Higher levels of intelligence must result from greater cause and effect, but greater cause and effect do not always result in higher levels of consciousness. Therefore observing greater intelligence means that there must be greater cause and effect, and usually also the other way around, though not always.


## Doesn't reverse causality break down the theory? {#doesn-t-reverse-causality-break-down-the-theory}

Maybe. But I've yet to see someone come back from the dead due to reverse causality.


## Doesn't the existence of an higher entity like a Spirit or God break down the theory? {#doesn-t-the-existence-of-an-higher-entity-like-a-spirit-or-god-break-down-the-theory}

It doesn't break down the theory, but does make it less likely.

-   It doesn't break down the theory because: The existence of a higher entity does not damage the argument itself. It does not disprove that consciousness is caused by increased integration of information. It could even very well be the Spirit itself that causes this increase in integration. It doesn't disprove that consciousness is not physical either. If you think about it, the existence of a Spirit and the fact that consciousness is physical are not mutually exclusive ideas as commonly thought. They could very well both be true[^fn:3].

-   But it does make it less likely because: Probability discourages the case described above. Having both A _and_ B be true is always less likely than having A _or_ B true. Therefore in the following scenario:
    -   Is it more probable that:

        1.  a higher entity exists _and_ directly causes consciousness
        2.  a higher entity exists _and_ consciousness is caused by integration of information
        3.  consciousness is caused by integration of information independent of whether a higher entity exists or not
        4.  a higher entity exists independent of whether consciousness is caused by integration of information or not

        (5. We are not considering a case where neither the theory nor the existence of a higher entity are true because then the entire theory would be false and we have bigger problems then whether a Spirit or God breaks down the theory.)

Option 3 and 4 are equally likely to each other, and both are more likely than option 1 and 2 (which are also equally likely to each other).

[^fn:1]: Note that the magnitude of the mass doesn't matter here. We just need a binary classification in this case. If an object produces a cause and effect (of any magnitude), it is intelligent. Otherwise, it isn't, and may or may not even exist.
[^fn:2]: We have solid empirical for this. Look no further than the countless studies on perception of media which integrate multiple senses (eg: film and animation), and attempts to separate these into individual perceived components (spoiler: you can't).
[^fn:3]: Also beware of correlation vs causation here. Just because a Spirit or God exists and appears to "cause" consciousness does not mean that it actually directly does. It could simply be that the Spirit causes more integration of information, or promotes something else which is actually the root cause.